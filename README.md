# ğŸ§ Audio Engine

A timeline-based audio rendering engine that generates final audio output from structured JSON timeline files.
The engine reads timestamped audio events and renders them into a single, mixed audio track with precise control over timing, layering, and transitions.

## ğŸš€ Features

### Core Engine
- **Timeline-based audio execution** â€” Precise timestamp control
- **Multi-layer audio mixing** â€” Voice, music, ambience, SFX tracks
- **Deterministic rendering** â€” Same input â†’ same output
- **JSON-driven and easy to extend**

### Professional DSP
- **EQ System** â€” Intent-based presets (`dialogue_clean`, `music_bed`, etc.)
- **Advanced Fade Curves** â€” Linear, logarithmic, exponential fades
- **Compressor** â€” Dialogue compression with configurable settings
- **Ducking** â€” Audacity-style envelope-based ducking
- **LUFS Loudness** â€” Industry-standard loudness normalization
- **Normalization** â€” Peak and LUFS-based mastering

### Intelligent Features
- **SFX Semantic Roles** â€” Impact, movement, ambience, interaction, texture
- **Scene Energy System** â€” 0.0-1.0 intensity mapping
- **Dialogue Density Analysis** â€” Automatic music gain adjustment
- **Scene Crossfades** â€” Smooth transitions between scenes
- **Auto-Fix Overlaps** â€” Automatically resolves clip conflicts

### Cinematic Logic
- **Dynamic music transitions**
- **Energy-based sound design**
- **Silence as a narrative device**

## ğŸ“¥ Input: Timeline JSON

The engine consumes a JSON file describing when and how audio assets should play.

```json
{
  "project": {
    "name": "My Audio Drama",
    "duration": 120.0
  },
  "settings": {
    "normalize": true,
    "loudness": { "enabled": true, "target_lufs": -20.0 }
  },
  "tracks": [
    {
      "id": "music",
      "type": "music",
      "role": "background",
      "eq_preset": "music_bed",
      "clips": []
    }
  ],
  "scenes": [
    {
      "id": "scene_1",
      "start": 0,
      "duration": 40,
      "energy": 0.4,
      "tracks": {
        "music": [{ "file": "audio/music/intro.mp3", "loop": true }],
        "dialogue": [{ "file": "audio/voice/intro.wav", "offset": 2 }]
      }
    }
  ]
}
```

## âš™ï¸ How It Works

1. **Parses** the timeline JSON
2. **Validates** input and checks file existence
3. **Preprocesses** scenes into clips with merged rules
4. **Auto-fixes** overlapping clips
5. **Processes** each track with DSP effects (EQ, compression, ducking, fades)
6. **Mixes** tracks together
7. **Masters** the output (LUFS normalization, peak limiting)
8. **Exports** final audio file

## ğŸ§© Supported Audio Types

| Type | Description |
|------|-------------|
| ğŸ™ï¸ **Dialogue** | Voice tracks with compression and clarity EQ |
| ğŸŒ¿ **Ambience** | Looped or timed background atmosphere |
| ğŸµ **Music** | Background music with energy-based gain |
| ğŸ”Š **SFX** | Sound effects with semantic role processing |

## ğŸ› ï¸ Installation

```bash
# Clone the repository
git clone <repository-url>
cd audio_engine

# Create virtual environment
python -m venv venv
.\venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt
```

## ğŸ“– Usage

```bash
python main.py <timeline.json> <output.wav>

# Example
python main.py timeline.json output/final.wav
```

## ğŸ“ Project Structure

```
audio_engine/
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ renderer/               # Core rendering pipeline
â”‚   â”œâ”€â”€ timeline_renderer.py   # Main orchestrator
â”‚   â”œâ”€â”€ clip_processor.py      # Clip-level DSP
â”‚   â”œâ”€â”€ track_mixer.py         # Track-level mixing
â”‚   â””â”€â”€ master_processor.py    # Master processing
â”œâ”€â”€ dsp/                    # Signal processing modules
â”‚   â”œâ”€â”€ eq.py                  # EQ system
â”‚   â”œâ”€â”€ eq_presets.py          # Intent-based presets
â”‚   â”œâ”€â”€ fade_curves.py         # Advanced fade curves
â”‚   â”œâ”€â”€ fades.py               # Fade application
â”‚   â”œâ”€â”€ ducking.py             # Envelope-based ducking
â”‚   â”œâ”€â”€ compression.py         # Dialogue compression
â”‚   â”œâ”€â”€ loudness.py            # LUFS measurement
â”‚   â”œâ”€â”€ normalization.py       # Peak normalization
â”‚   â”œâ”€â”€ balance.py             # Role-based loudness
â”‚   â””â”€â”€ sfx_processor.py       # SFX semantic processing
â”œâ”€â”€ utils/                  # Utility modules
â”‚   â”œâ”€â”€ logger.py              # Logging system
â”‚   â”œâ”€â”€ dialogue_density.py    # Density analysis
â”‚   â””â”€â”€ energy.py              # Energy mapping
â”œâ”€â”€ scene_preprocessor.py   # Scene â†’ clip expansion
â”œâ”€â”€ validation.py           # Input validation
â”œâ”€â”€ autofix.py              # Overlap resolution
â”œâ”€â”€ docs/                   # Documentation
â””â”€â”€ test/                   # Test files
```

## ğŸ“š Documentation

- [Timeline JSON Schema](docs/timeline_json_schema.md) â€” Complete JSON specification
- [EQ System](docs/eq_system_v1.md) â€” Intent-based EQ implementation
- [Fade Curves](docs/FADE_CURVES_IMPLEMENTATION.md) â€” Advanced fade curve details
- [SFX Implementation](docs/SFX_IMPLEMENTATION.md) â€” Semantic role processing
- [Engine Analysis](docs/AUDIO_ENGINE_ANALYSIS.md) â€” Architecture overview
- [Design Decisions](docs/DESIGN_DECISIONS.md) â€” Engineering rationale

## ğŸ¯ Output

- **WAV format** â€” High-quality uncompressed audio
- **Configurable sample rate** â€” 44.1kHz, 48kHz, etc.
- **Loudness normalized** â€” Streaming-ready (-20 LUFS default)

## ğŸ“‹ Requirements

- Python 3.8+
- pydub
- numpy
- scipy
- pyloudnorm

---

*Last Updated: February 2026*
